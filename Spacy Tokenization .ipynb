{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414db399",
   "metadata": {},
   "source": [
    "***Importing Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4255098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5e501",
   "metadata": {},
   "source": [
    "***Create blank language object and tokenize words in a sentence***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3757a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025e5e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\n",
      "Ahmed\n",
      "visited\n",
      "lahore\n",
      "and\n",
      "there\n",
      "he\n",
      "love\n",
      "the\n",
      "digital\n",
      "museum\n",
      "and\n",
      "the\n",
      "entrance\n",
      "fee\n",
      "was\n",
      "150\n",
      "for\n",
      "Pakistani\n",
      "'s\n",
      "and\n",
      "500\n",
      "for\n",
      "other\n",
      "nationalities\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mr. Ahmed visited lahore and there he love the digital museum and the entrance fee was 150 for Pakistani's and 500 for other nationalities\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098bac16",
   "metadata": {},
   "source": [
    "***Indexing for Grabbing Tokens***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313c0ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lahore"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314e4f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "and"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3501681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "the\n",
      "Zoo\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('''\"Let's go to the Zoo!\"''')\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99e56cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6f0551c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s go to the Zoo"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad278041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a260bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f8878",
   "metadata": {},
   "source": [
    "***Spanning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34bf119f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's go to the"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[0:6]\n",
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2d842758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c92f2",
   "metadata": {},
   "source": [
    "***Token Attributes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab8d88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Ahmed asked for $ from me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84d59bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ahmed"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = doc[0]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e2c1867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e64b6846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc907b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92fe4b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6346db48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = doc[2]\n",
    "token2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28186735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token5 = doc[5]\n",
    "token5.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91edaa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token5.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efa4d9d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahmed ==> index:  0 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "asked ==> index:  1 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "for ==> index:  2 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "$ ==> index:  3 is_alpha: False is_punct: False like_num: False is_currency: True\n",
      "from ==> index:  4 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      "me ==> index:  5 is_alpha: True is_punct: False like_num: False is_currency: False\n",
      ". ==> index:  6 is_alpha: False is_punct: True like_num: False is_currency: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha, \n",
    "          \"is_punct:\", token.is_punct, \n",
    "          \"like_num:\", token.like_num,\n",
    "          \"is_currency:\", token.is_currency,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955bcd5a",
   "metadata": {},
   "source": [
    "***Collecting emails from Student information sheet***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdc1191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " ' Name      birth day           email\\n',\n",
       " ' -------   ----------          ------\\n',\n",
       " ' Virat     5 June, 1882      virat@kohli.com\\n',\n",
       " ' Maria     12 April, 2001    maria@sharapova.com\\n',\n",
       " ' Serena    24 June, 1998     serena@williams.com\\n',\n",
       " ' Joe        1 May, 1997      joe@root.com']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"C:/Users/user/Desktop/student.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11c7097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n Dayton high school, 8th grade students information\\n ==================================================\\n \\n  Name      birth day           email\\n  -------   ----------          ------\\n  Virat     5 June, 1882      virat@kohli.com\\n  Maria     12 April, 2001    maria@sharapova.com\\n  Serena    24 June, 1998     serena@williams.com\\n  Joe        1 May, 1997      joe@root.com'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a48ae147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "emails = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3acc8e2",
   "metadata": {},
   "source": [
    "***Supporting Urdu Langague***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41c74b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کیا False False\n",
      "آپ False False\n",
      "مہربانی False False\n",
      "کر False False\n",
      "کے False False\n",
      "مجھے False False\n",
      "500 False True\n",
      "روپے False False\n",
      "قرض False False\n",
      "دیں False False\n",
      "گے False False\n",
      "؟ False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"hi\")\n",
    "\n",
    "doc = nlp(\"کیا آپ مہربانی کر کے مجھے 500 روپے قرض دیں گے؟\")\n",
    "for token in doc:\n",
    "    print(token, token.is_currency, token.like_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8deff",
   "metadata": {},
   "source": [
    "***Customizing Tokenizer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b56dfa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd527013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"},\n",
    "])\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2100872",
   "metadata": {},
   "source": [
    "***Sentence Tokenization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5d18d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f1d34c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x106b1ff77d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4ffc6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Ahmed visited lahore and there he love the digital museum.\n",
      "The entrance fee was 150 for Pakistani's and 500 for other nationalities\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Mr. Ahmed visited lahore and there he love the digital museum. The entrance fee was 150 for Pakistani's and 500 for other nationalities\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20ac4a",
   "metadata": {},
   "source": [
    "# Collect all the dataset websites from the text using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "485ce9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67f87538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "url = []\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        url.append(token.text)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f953de05",
   "metadata": {},
   "source": [
    "# Extract all money transaction from below sentence along with currency. Output should be, two$ 500 €. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9522b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony False\n",
      "gave False\n",
      "two False\n",
      "$ True\n",
      "to False\n",
      "Peter False\n",
      ", False\n",
      "Bruce False\n",
      "gave False\n",
      "500 False\n",
      "€ True\n",
      "to False\n",
      "Steve False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tony gave two $ to Peter, Bruce gave 500 € to Steve\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eafb9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "doc = nlp(transactions)\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
